{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pistonball_CleanRL import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from supersuit import color_reduction_v0, frame_stack_v1, resize_v1\n",
    "from pettingzoo.butterfly import pistonball_v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(nn.Module):\n",
    "    def __init__(self, num_actions):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            self._layer_init(nn.Conv2d(4, 32, 3, padding=1)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            self._layer_init(nn.Conv2d(32, 64, 3, padding=1)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            self._layer_init(nn.Conv2d(64, 128, 3, padding=1)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            self._layer_init(nn.Linear(128 * 8 * 8, 512)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.actor = self._layer_init(nn.Linear(512, num_actions), std=0.01)\n",
    "        self.critic = self._layer_init(nn.Linear(512, 1))\n",
    "\n",
    "    def _layer_init(self, layer, std=np.sqrt(2), bias_const=0.0):\n",
    "        torch.nn.init.orthogonal_(layer.weight, std)\n",
    "        torch.nn.init.constant_(layer.bias, bias_const)\n",
    "        return layer\n",
    "\n",
    "    def get_value(self, x):\n",
    "        return self.critic(self.network(x / 255.0))\n",
    "\n",
    "    def forward(self, x, action=None):\n",
    "        hidden = self.network(x / 255.0)\n",
    "        logits = self.actor(hidden)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        return action, probs.log_prob(action), probs.entropy(), self.critic(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(nn.Module):\n",
    "    def __init__(self, num_actions, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            self._layer_init(nn.Conv2d(4, 32, 3, padding=1)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            self._layer_init(nn.Conv2d(32, 64, 3, padding=1)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            self._layer_init(nn.Conv2d(64, 128, 3, padding=1)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            self._layer_init(nn.Linear(128 * 8 * 8, 512)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.action_embedding1 = nn.Embedding(num_actions, embedding_dim)\n",
    "        self.action_embedding2 = nn.Embedding(num_actions, embedding_dim)\n",
    "        \n",
    "        self.actor = self._layer_init(nn.Linear(512 + 2 * embedding_dim, num_actions))\n",
    "        self.critic = self._layer_init(nn.Linear(512 + 2 * embedding_dim, 1))\n",
    "    \n",
    "    def _layer_init(self, layer, std=np.sqrt(2), bias_const=0.0):\n",
    "        torch.nn.init.orthogonal_(layer.weight, std)\n",
    "        torch.nn.init.constant_(layer.bias, bias_const)\n",
    "        return layer\n",
    "    \n",
    "    def get_value(self, x):\n",
    "        return self.critic(self.network(x / 255.0))\n",
    "    \n",
    "    def get_action_and_value(self, x, actions):\n",
    "        action1, action2 = actions\n",
    "        hidden = self.network(x / 255.0)\n",
    "        action1_embedded = self.action_embedding1(action1).unsqueeze(0)\n",
    "        action2_embedded = self.action_embedding2(action2).unsqueeze(0)\n",
    "        hidden = torch.cat((hidden, action1_embedded, action2_embedded), dim=1)\n",
    "        logits = self.actor(hidden)\n",
    "        probs = Categorical(logits=logits)\n",
    "        action = probs.sample()\n",
    "        return action, probs.log_prob(action), probs.entropy(), self.critic(hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        num_agents = x.shape[0]\n",
    "        x = x.unsqueeze(1)\n",
    "        actions = torch.ones(num_agents + 2, dtype=torch.int)\n",
    "        log_probs = torch.zeros(num_agents)\n",
    "        entropies = torch.zeros(num_agents)\n",
    "        values = torch.zeros(num_agents)\n",
    "        \n",
    "        for ind in range(num_agents - 1, -1, -1):\n",
    "            depend_actions = actions[ind:ind+2]\n",
    "            actions[ind], log_probs[ind], entropies[ind], values[ind] = self.get_action_and_value(x[ind], depend_actions)\n",
    "        return actions[:-2], log_probs, entropies, values\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "frame_size = (64, 64)\n",
    "stack_size = 4\n",
    "\n",
    "env = pistonball_v6.parallel_env(render_mode=\"rgb_array\", continuous=False)\n",
    "env = color_reduction_v0(env)\n",
    "env = resize_v1(env, frame_size[0], frame_size[1])\n",
    "env = frame_stack_v1(env, stack_size=stack_size)\n",
    "next_obs, info = env.reset(seed=None)\n",
    "obs: torch.Tensor = batchify_obs(next_obs, device)\n",
    "print(next_obs[\"piston_0\"].shape)\n",
    "print(obs.shape)\n",
    "print(env.unwrapped.screen_width, env.unwrapped.screen_height)\n",
    "print(obs.unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = env.action_space(env.possible_agents[0]).n\n",
    "agent = Agent_ADG(num_actions=num_actions).to(device)\n",
    "\n",
    "agent(obs)\n",
    "# obs = obs[0].unsqueeze(0)\n",
    "# action, log_prob, entropy, value = agent(obs) #(20, 128, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents = 20\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "action_base = torch.ones(num_agents + 2, dtype=torch.int).to(device)\n",
    "action = torch.zeros(num_agents, dtype=torch.int)\n",
    "action_base[:-2] = action\n",
    "action_base.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义线性层\n",
    "linear = nn.Linear(3, 2)\n",
    "x = torch.randn(4, 3)  # mini-batch 大小为 4\n",
    "y = linear(x)\n",
    "\n",
    "# 假设目标值\n",
    "target = torch.randn(4, 2)\n",
    "criterion = nn.MSELoss(reduction='sum')  # 默认求和\n",
    "loss = criterion(y, target)\n",
    "loss.backward()\n",
    "\n",
    "print(linear.weight.grad)  # 梯度是累加的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "action_embedding = nn.Embedding(3, 64)\n",
    "out = action_embedding(torch.tensor([0, 1, 2]))\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
